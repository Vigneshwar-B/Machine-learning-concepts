{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afe9712",
   "metadata": {},
   "outputs": [],
   "source": [
    "Day-15 Hands on practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a514b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "1.Write a NumPy program to create a structured array from given student name, height, class and their data types.\n",
    "Now sort the array on height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd105da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original array:\n",
      "[(b'James', 5, 48.5 ) (b'Nail', 6, 52.5 ) (b'Paul', 5, 42.1 )\n",
      " (b'Pit', 5, 40.11)]\n",
      "Sort by height\n",
      "[(b'Pit', 5, 40.11) (b'Paul', 5, 42.1 ) (b'James', 5, 48.5 )\n",
      " (b'Nail', 6, 52.5 )]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "data_type = [('name', 'S15'), ('class', int), ('height', float)]\n",
    "students_details = [('James', 5, 48.5), ('Nail', 6, 52.5),('Paul', 5, 42.10), ('Pit', 5, 40.11)]\n",
    "# create a structured array\n",
    "students = np.array(students_details, dtype=data_type)   \n",
    "print(\"Original array:\")\n",
    "print(students)\n",
    "print(\"Sort by height\")\n",
    "print(np.sort(students, order='height'))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63329cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "2.Write a NumPy program to generate five random numbers from the normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8a86467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.42151331 -1.45287769  0.46280345 -0.25329229  0.33750508]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.random.normal(size=5)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9b3ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "3.Write a Pandas program to join the two given data frames\n",
    "along columns and assign all data.\n",
    "Test Data:\n",
    "student_data1:\n",
    "student_id name marks\n",
    "S1 Danniella Fenton 200\n",
    "S2 Ryder Storey 210\n",
    "S3 Bryce Jensen 190\n",
    "S4 Ed Bernal 222\n",
    "S5 Kwame Morin 199\n",
    "student_data2:\n",
    "student_id name marks\n",
    "S4 Scarlette Fisher 201\n",
    "S5 Carla Williamson 200\n",
    "S6 Dante Morse 198\n",
    "S7 Kaiser William 219"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8adccb38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrames:\n",
      "  student_id              name  marks\n",
      "0         S1  Danniella Fenton    200\n",
      "1         S2      Ryder Storey    210\n",
      "2         S3      Bryce Jensen    190\n",
      "3         S4         Ed Bernal    222\n",
      "4         S5       Kwame Morin    199\n",
      "-------------------------------------\n",
      "  student_id              name  marks\n",
      "0         S4  Scarlette Fisher    201\n",
      "1         S5  Carla Williamson    200\n",
      "2         S6       Dante Morse    198\n",
      "3         S7    Kaiser William    219\n",
      "4         S8   Madeeha Preston    201\n",
      "\n",
      "Join the said two dataframes along rows:\n",
      "  student_id              name  marks\n",
      "0         S1  Danniella Fenton    200\n",
      "1         S2      Ryder Storey    210\n",
      "2         S3      Bryce Jensen    190\n",
      "3         S4         Ed Bernal    222\n",
      "4         S5       Kwame Morin    199\n",
      "0         S4  Scarlette Fisher    201\n",
      "1         S5  Carla Williamson    200\n",
      "2         S6       Dante Morse    198\n",
      "3         S7    Kaiser William    219\n",
      "4         S8   Madeeha Preston    201\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "student_data1 = pd.DataFrame({\n",
    "        'student_id': ['S1', 'S2', 'S3', 'S4', 'S5'],\n",
    "         'name': ['Danniella Fenton', 'Ryder Storey', 'Bryce Jensen', 'Ed Bernal', 'Kwame Morin'], \n",
    "        'marks': [200, 210, 190, 222, 199]})\n",
    "\n",
    "student_data2 = pd.DataFrame({\n",
    "        'student_id': ['S4', 'S5', 'S6', 'S7', 'S8'],\n",
    "        'name': ['Scarlette Fisher', 'Carla Williamson', 'Dante Morse', 'Kaiser William', 'Madeeha Preston'], \n",
    "        'marks': [201, 200, 198, 219, 201]})\n",
    "\n",
    "print(\"Original DataFrames:\")\n",
    "print(student_data1)\n",
    "print(\"-------------------------------------\")\n",
    "print(student_data2)\n",
    "print(\"\\nJoin the said two dataframes along rows:\")\n",
    "result_data = pd.concat([student_data1, student_data2])\n",
    "print(result_data)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4433e60a",
   "metadata": {},
   "source": [
    "4.Write a Pandas program to split the following data frame\n",
    "into groups based on school code. Also check the type of\n",
    "GroupBy object.\n",
    "Test Data:\n",
    "school class name date_Of_Birth age height weight\n",
    "address\n",
    "s001 V Alberto Franco 15/05/2002 12 173 35\n",
    "street1\n",
    "s002 V Gino Mcneill 17/05/2002 12 192 32\n",
    "street2\n",
    "s003 VI Ryan Parkes 16/02/1999 13 186 33\n",
    "street3\n",
    "s001 VI Eesha Hinton 25/09/1998 13 167 30\n",
    "street1\n",
    "s002 V Gino Mcneill 11/05/2002 14 151 31\n",
    "street2\n",
    "s004 VI David Parkes 15/09/1997 12 159 32\n",
    "street4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5626580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "   school_code class            name date_Of_Birth   age  height  weight  \\\n",
      "S1        s001     V  Alberto Franco     15/05/2002   12     173      35   \n",
      "S2        s002     V    Gino Mcneill     17/05/2002   12     192      32   \n",
      "S3        s003    VI     Ryan Parkes     16/02/1999   13     186      33   \n",
      "S4        s001    VI    Eesha Hinton     25/09/1998   13     167      30   \n",
      "S5        s002     V    Gino Mcneill     11/05/2002   14     151      31   \n",
      "S6        s004    VI    David Parkes     15/09/1997   12     159      32   \n",
      "\n",
      "    address  \n",
      "S1  street1  \n",
      "S2  street2  \n",
      "S3  street3  \n",
      "S4  street1  \n",
      "S5  street2  \n",
      "S6  street4  \n",
      "\n",
      "Split the said data on school_code wise:\n",
      "\n",
      "Group:\n",
      "s001\n",
      "   school_code class            name date_Of_Birth   age  height  weight  \\\n",
      "S1        s001     V  Alberto Franco     15/05/2002   12     173      35   \n",
      "S4        s001    VI    Eesha Hinton     25/09/1998   13     167      30   \n",
      "\n",
      "    address  \n",
      "S1  street1  \n",
      "S4  street1  \n",
      "\n",
      "Group:\n",
      "s002\n",
      "   school_code class          name date_Of_Birth   age  height  weight  \\\n",
      "S2        s002     V  Gino Mcneill     17/05/2002   12     192      32   \n",
      "S5        s002     V  Gino Mcneill     11/05/2002   14     151      31   \n",
      "\n",
      "    address  \n",
      "S2  street2  \n",
      "S5  street2  \n",
      "\n",
      "Group:\n",
      "s003\n",
      "   school_code class         name date_Of_Birth   age  height  weight  address\n",
      "S3        s003    VI  Ryan Parkes     16/02/1999   13     186      33  street3\n",
      "\n",
      "Group:\n",
      "s004\n",
      "   school_code class          name date_Of_Birth   age  height  weight  \\\n",
      "S6        s004    VI  David Parkes     15/09/1997   12     159      32   \n",
      "\n",
      "    address  \n",
      "S6  street4  \n",
      "\n",
      "Type of the object:\n",
      "<class 'pandas.core.groupby.generic.DataFrameGroupBy'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vigne\\AppData\\Local\\Temp\\ipykernel_9476\\2973386871.py:19: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for name,group in result:\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "#pd.set_option('display.max_columns', None)\n",
    "student_data = pd.DataFrame({\n",
    "    'school_code': ['s001','s002','s003','s001','s002','s004'],\n",
    "    'class': ['V', 'V', 'VI', 'VI', 'V', 'VI'],\n",
    "    'name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Gino Mcneill', 'David Parkes'],\n",
    "    'date_Of_Birth ': ['15/05/2002','17/05/2002','16/02/1999','25/09/1998','11/05/2002','15/09/1997'],\n",
    "    'age': [12, 12, 13, 13, 14, 12],\n",
    "    'height': [173, 192, 186, 167, 151, 159],\n",
    "    'weight': [35, 32, 33, 30, 31, 32],\n",
    "    'address': ['street1', 'street2', 'street3', 'street1', 'street2', 'street4']},\n",
    "    index=['S1', 'S2', 'S3', 'S4', 'S5', 'S6'])\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(student_data)\n",
    "print('\\nSplit the said data on school_code wise:')\n",
    "result = student_data.groupby(['school_code'])\n",
    "for name,group in result:\n",
    "    print(\"\\nGroup:\")\n",
    "    print(name)\n",
    "    print(group)\n",
    "print(\"\\nType of the object:\")\n",
    "print(type(result))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d9c86991",
   "metadata": {},
   "source": [
    "5.Write a NumPy program to find the most frequent value in\n",
    "an array.\n",
    "Original array:\n",
    "[6 9 5 1 7 5 1 0 1 5 5 0 8 9 0 7 0 7 6 5 1 1 9 5 3 8 7 9 6 3 4 5\n",
    "9 7 2 7 0 2 2 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e27b35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original array:\n",
      "[1 2 3 4 5 1 2 1 1 1]\n",
      "Most frequent value in the above array:\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "  \n",
    "  \n",
    "# create array\n",
    "x = np.array([1,2,3,4,5,1,2,1,1,1])\n",
    "print(\"Original array:\")\n",
    "print(x)\n",
    "  \n",
    "print(\"Most frequent value in the above array:\")\n",
    "print(np.bincount(x).argmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d45fd94",
   "metadata": {},
   "source": [
    "6.Write a Pandas program to append rows to an existing\n",
    "DataFrame and display the combined data.\n",
    "Test Data:\n",
    "tudent_data1\n",
    "student_id name marks\n",
    "S1 Danniella Fenton 200\n",
    "S2 Ryder Storey 210\n",
    "S3 Bryce Jensen 190\n",
    "S4 Ed Bernal 222\n",
    "S5 Kwame Morin 199\n",
    "New Row(s)\n",
    "student_id S6\n",
    "name Scarlette Fisher\n",
    "marks 205\n",
    "dtype: object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "457a91aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrames:\n",
      "  student_id              name  marks\n",
      "0         S1  Danniella Fenton    200\n",
      "1         S2      Ryder Storey    210\n",
      "2         S3      Bryce Jensen    190\n",
      "3         S4         Ed Bernal    222\n",
      "4         S5       Kwame Morin    199\n",
      "\n",
      "New Row(s)\n",
      "student_id                  S6\n",
      "name          Scarlette Fisher\n",
      "marks                      205\n",
      "dtype: object\n",
      "\n",
      "Combined Data:\n",
      "  student_id              name  marks\n",
      "0         S1  Danniella Fenton    200\n",
      "1         S2      Ryder Storey    210\n",
      "2         S3      Bryce Jensen    190\n",
      "3         S4         Ed Bernal    222\n",
      "4         S5       Kwame Morin    199\n",
      "5         S6  Scarlette Fisher    205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vigne\\AppData\\Local\\Temp\\ipykernel_9476\\3505274060.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_data = student_data1.append(s6, ignore_index = True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "student_data1 = pd.DataFrame({\n",
    "        'student_id': ['S1', 'S2', 'S3', 'S4', 'S5'],\n",
    "         'name': ['Danniella Fenton', 'Ryder Storey', 'Bryce Jensen', 'Ed Bernal', 'Kwame Morin'], \n",
    "        'marks': [200, 210, 190, 222, 199]})\n",
    "\n",
    "s6 = pd.Series(['S6', 'Scarlette Fisher', 205], index=['student_id', 'name', 'marks'])\n",
    "print(\"Original DataFrames:\")\n",
    "print(student_data1)\n",
    "print(\"\\nNew Row(s)\")\n",
    "print(s6)\n",
    "combined_data = student_data1.append(s6, ignore_index = True)\n",
    "print(\"\\nCombined Data:\")\n",
    "print(combined_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d3860b",
   "metadata": {},
   "source": [
    "7.Write a NumPy program to partition a given array in a specified position and move all the smaller elements values to the left\n",
    "of the partition, and the remaining values to the right, in arbitrary order (based on random choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "033eeb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original array:\n",
      "[ 70  50  20  30 -11  60  50  40]\n",
      "\n",
      "After partitioning on 4 the position:\n",
      "[-11  30  20  40  50  50  60  70]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "nums = np.array([70, 50, 20, 30, -11, 60, 50, 40])\n",
    "print(\"Original array:\")\n",
    "print(nums)\n",
    "print(\"\\nAfter partitioning on 4 the position:\")\n",
    "print(np.partition(nums, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb63415",
   "metadata": {},
   "source": [
    "8.\tWrite a python code to perform a Transpose of matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "902939dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 3]\n",
      " [2 4]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a=np.array([[1,2],[3,4]])\n",
    "b=a.transpose()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a3ef91",
   "metadata": {},
   "source": [
    "9.Write a NumPy program to sort a given array of shape 2 along the first axis, last axis and on flattened array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ede9e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original array:\n",
      "[[10 40]\n",
      " [30 20]]\n",
      "Sort the array along the first axis:\n",
      "[[10 20]\n",
      " [30 40]]\n",
      "Sort the array along the last axis:\n",
      "[[10 40]\n",
      " [20 30]]\n",
      "Sort the flattened array:\n",
      "[10 20 30 40]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.array([[10,40],[30,20]])\n",
    "print(\"Original array:\")\n",
    "print(a)\n",
    "print(\"Sort the array along the first axis:\")\n",
    "print(np.sort(a, axis=0))\n",
    "print(\"Sort the array along the last axis:\")\n",
    "print(np.sort(a))\n",
    "print(\"Sort the flattened array:\")\n",
    "print(np.sort(a, axis=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649aa84c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
